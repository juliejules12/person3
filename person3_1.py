# -*- coding: utf-8 -*-
"""person3-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mjF7Ih01gfNllBoG31qqF9Pk5KrR1giQ

# Week 3 AI Tools Assignment - Task 2
## Deep Learning with TensorFlow (MNIST Handwritten Digits)
This notebook implements a simple Convolutional Neural Network (CNN) using TensorFlow to classify the MNIST handwritten digit dataset.
"""

# Import required libraries
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Print TensorFlow version
print(f"TensorFlow version: {tf.__version__}")

"""## Load and Preprocess Data
Load the MNIST dataset, normalize pixel values, and reshape the data to add the channel dimension (for CNNs).

"""

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()

# Normalize pixel values to [0, 1]
x_train, x_test = x_train / 255.0, x_test / 255.0

# Reshape data to add a channel dimension (28, 28, 1)
x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

# Print dataset shapes
print(f"Training set shape: {x_train.shape}, Labels: {y_train.shape}")
print(f"Test set shape: {x_test.shape}, Labels: {y_test.shape}")

"""## Build the CNN Model
Define a simple CNN model with:
- Two convolutional layers (32 and 64 filters)
- Max pooling layers
- A flatten layer
- A dense hidden layer
- A final output layer with softmax activation

"""

# Build a Sequential CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Display the model summary
model.summary()

"""## Compile the Model
Use the Adam optimizer, sparse categorical cross-entropy loss, and track accuracy.

"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""## Train the Model
Train the model for 5 epochs and validate on the test set.

"""

history = model.fit(x_train, y_train, epochs=5,
                    validation_data=(x_test, y_test))

"""## Evaluate the Model
Evaluate the trained model on the test set and print the test accuracy.

"""

test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f"Test accuracy: {test_acc:.4f}")

"""## Visualize Training History
Plot training and validation accuracy over the epochs.

"""

plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Model Accuracy over Epochs')
plt.legend()
plt.grid(True)
plt.show()
model.save("mnist_cnn_model.h5")
model.save("model.h5")

"""## Ethical Reflection
AI systems like this can achieve high accuracy on digit classification tasks. However, itâ€™s important to consider potential biases in training data, model fairness, and accessibility. For example, in real-world applications, poor handwriting or cultural variations in digits might affect model performance. We should also ensure that AI systems are explainable and transparent to build user trust and accountability.

"""

from google.colab import files
files.download('mnist_cnn_model.h5')